{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Description\n",
    "\"\"\"\n",
    "\n",
    "Last modified 11.02.2016\n",
    "    Added mongoDB support\n",
    "    pandas avr_table dumps to csv file in 'folder' directory \n",
    "\n",
    "08.02.2016\n",
    "Pandas functionality added, now can be saved to database\n",
    "\n",
    "New - sifting works correctly, \n",
    "        in dataD images which are sifted indicated as isgood=False, \n",
    "        fits now use parameter sigma = 'yerr' to calculate fit,\n",
    "        \n",
    "\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To restart remote kernels run code below before restarting this kernel\n",
    "rc1.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "%%px --targets 0 \n",
    "# to enter kernel qtconsole run this code\n",
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports and initialization\n",
    "%pylab inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "par_dir = os.path.split(os.getcwd())[0]\n",
    "if par_dir not in sys.path:\n",
    "    sys.path.append(par_dir)\n",
    "import inspect\n",
    "import pickle\n",
    "import imp\n",
    "import re\n",
    "import json\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "\n",
    "# from IPython.html import widgets\n",
    "# from IPython.display import display\n",
    "# from IPython.html.widgets import interact, interactive, fixed\n",
    "\n",
    "\n",
    "import thulium_python_lib.usefull_functions as usfuncs\n",
    "import thulium_python_lib.image_processing_new as impr\n",
    "\n",
    "import ipyparallel as ipp\n",
    "ipp.CompositeError.tb_limit = 1\n",
    "\n",
    "rc1 = ipp.Client()\n",
    "lview = rc1.load_balanced_view()\n",
    "dview = rc1.direct_view()\n",
    "dview['par_dir'] = par_dir\n",
    "# with dview.sync_imports():\n",
    "#     import sys, os    \n",
    "%px import sys, os\n",
    "%px if par_dir not in sys.path: sys.path.append(par_dir)\n",
    "%px import thulium_python_lib.image_processing_new as impr\n",
    "%px import imp\n",
    "%px from ipyparallel import bind_kernel; bind_kernel()\n",
    "\n",
    "import datetime\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "# start mongoDB client (mongod server should be launched)\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "meas_database = client.measData.meas_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to reload library on remote and local engine\n",
    "# %px imp.reload(impr)\n",
    "# imp.reload(impr)\n",
    "# imp.reload(usfuncs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose working directory and measurement folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# smth like 'D:\\!Data\\2015_08_20' for lab and like '/Users/artemgolovizin/Downloads/2015_08_20' for mac\n",
    "os.chdir(r'\\\\BIGONE\\!Data\\2016_02_04')\n",
    "# os.chdir(r'/Users/artemgolovizin/Downloads/2015_08_20/')\n",
    "# print('Current directory', os.getcwd());\n",
    "current_directory = os.path.split(os.getcwd())[-1]\n",
    "# Create folder 'Figures' for saving individual plot\n",
    "if not os.path.exists('Figures'):\n",
    "    os.makedirs('Figures')\n",
    "    print('Folder Figures has been created')\n",
    "working_directory = ''\n",
    "folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify working folder\n",
    "folder = '06 T/'\n",
    "working_directory = os.path.join(os.getcwd(),folder)\n",
    "# print('Working directory', working_directory)\n",
    "\n",
    "dirs = [x for x in os.listdir() if re.match('\\d',x)]\n",
    "meas_type, conf_params, x_lbl, y_lbl, xaxis_calib = impr.get_x_calibration(folder, dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, rearange, average and calibrate\n",
    " Constract loader and averager. For available parameters see help('instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create loader\n",
    "loader  = impr.Load_Image(dview)\n",
    "# downloading images\n",
    "all_data = loader(working_directory,lview)\n",
    "\n",
    "# rearranging to dictionary\n",
    "dataD = impr.rearrange_data(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create averager\n",
    "averager = impr.Avr_Image(dview,do_sifting=True,conf_int=0.2)\n",
    "# averaging data\n",
    "avr_dataD = averager(dataD,lview)\n",
    "\n",
    "# construct new data dictionary without image and calibration atoms number, size and x-axis\n",
    "navrD = impr.mod_avrData(avr_dataD, xaxis_calib, impr.N_atoms(width=0.5, delta = 5), impr.real_size)\n",
    "\n",
    "avr_table = impr.get_pandas_table2(navrD)\n",
    "# for plotting sifted image\n",
    "\n",
    "#imshow(imread('1 от частоты амплитудной модуляции аома верди (5) 3.9W/26ms/2_1.png'))\n",
    "#colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convention table for filenames\n",
    "impr.meas_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct data based on measurement type and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shot_typeN - for now only 1, if there will be calibration - 1 or more\n",
    "shot_typeN = 1\n",
    "\n",
    "# description to add to all_data.txt file\n",
    "description = dict()\n",
    "description['meas_type'] = meas_type\n",
    "description['x_label'] = x_lbl\n",
    "description['y_label'] = y_lbl\n",
    "\n",
    "#meas_type = 'T' # here one can specify type to get desired plots\n",
    "meas_type = 'LT'\n",
    "fit_func = None\n",
    "fits_list = []\n",
    "fig1, ax1 = subplots()\n",
    "if meas_type == 'T':\n",
    "    # construct data with cloud expansion on both coordinates\n",
    "    # first set of data  - Temperature X\n",
    "    d1 = impr.get_avr_data(navrD, shot_typeN, 'fit1D_x',2)\n",
    "    d1['fmt']='ro'\n",
    "    d1['label']='fit1D_x'\n",
    "    #impr.drop_by_number(d1,5)\n",
    "    #impr.drop_by_x(d1,130,160)\n",
    "\n",
    "    # second set of data  - Temperature Y\n",
    "    d2 = impr.get_avr_data(navrD, shot_typeN,  'fit1D_y',2)\n",
    "    d2['fmt']='bo'\n",
    "    d2['label'] = 'fit1D_y'\n",
    "    #impr.drop_by_number(d2,5)\n",
    "    \n",
    "    # fit cloud expansion\n",
    "    fit_func = usfuncs.cloud_expansion0\n",
    "    popt_T, pcov_T = curve_fit(fit_func, d1['x'], d1['y'], p0=(d1['y'][0],20))\n",
    "    perr_T = np.sqrt(np.diag(pcov_T))\n",
    "    fits_list.append([fit_func.__name__,list(popt_T), list(perr_T)])\n",
    "    popt_T2, pcov_T2 = curve_fit(fit_func, d2['x'], d2['y'], p0=(d2['y'][0], 20))\n",
    "    perr_T2 = np.sqrt(np.diag(pcov_T2))\n",
    "    fits_list.append([fit_func.__name__,list(popt_T2), list(perr_T2)])\n",
    "#     print('Fit parameters X, Y:\\n' + usfuncs.construct_fit_description(fit_func, list(zip(popt_T,popt_T2))))\n",
    "    \n",
    "    # plot data and fits \n",
    "    ax1.errorbar(**d2)\n",
    "    ax1.errorbar(**d1)\n",
    "    ax1.plot(linspace(min(d1['x']),max(d1['x']),100), fit_func(linspace(min(d1['x']),max(d1['x']),100),*popt_T),\n",
    "             'r', label='Tx=%.2f$\\pm$%.1f'%(popt_T[0],perr_T[0]))\n",
    "    ax1.plot(linspace(min(d2['x']),max(d2['x']),100), fit_func(linspace(min(d2['x']),max(d2['x']),100),*popt_T2),\n",
    "             'b', label='Ty=%.2f$\\pm$%.1f'%(popt_T2[0],perr_T2[0]))\n",
    "    ax1.set_xlim(min(d1['x'])-1, max(d1['x'])+1)\n",
    "    # add information about fits to description\n",
    "    description['fit1D_x'] =  popt_T\n",
    "    description['fit1D_y'] =  popt_T2\n",
    "    description['fit-function'] = fit_func.__name__\n",
    "else:\n",
    "    # construct data, param - what value to use\n",
    "    param = ['fit1D_x',0]\n",
    "    d1 = impr.get_avr_data(navrD, shot_typeN, *param)\n",
    "    d1['fmt']='ro'\n",
    "    d1['label']=param\n",
    "    #impr.drop_by_number(d1,*range(20,len(d1['x'])))\n",
    "    #impr.drop_by_x(d1,130,160)\n",
    "    \n",
    "    # fit_func - which function to use to fit data  here one can put conditions on meas_type to choose fit\n",
    "    popt_T = None\n",
    "    fit_func = usfuncs.exp_decay_no_bg\n",
    "    popt_T, pcov_T = curve_fit(fit_func, d1['x'], d1['y'], p0=(d1['y'][0], 100))\n",
    "#     #popt_T, pcov_T = curve_fit(fit_func, d1['x'], d1['y'], p0=(-d1['y'][0], d1['x'][argmin(d1['y'])],0.1,d1['y'][0]))\n",
    "#     print('Fit parameters:\\n' + usfuncs.construct_fit_description(fit_func, popt_T))\n",
    "    perr_T = np.sqrt(np.diag(pcov_T))\n",
    "    \n",
    "    # plot data and fits\n",
    "    ax1.errorbar(**d1)\n",
    "    if fit_func != None:\n",
    "        ax1.plot(linspace(min(d1['x']),max(d1['x']),100), fit_func(linspace(min(d1['x']),max(d1['x']),100),*popt_T),'k', label='fit X')\n",
    "        fit_label = fit_func.__name__ + ' fit:\\n' + usfuncs.construct_fit_description(fit_func, list(zip(popt_T,perr_T)),sep='$\\pm$')\n",
    "        ax1.text(0.01,0.01,fit_label,transform=ax1.transAxes)\n",
    "        description['fit'] =  popt_T\n",
    "        description['fit-function'] = fit_func.__name__\n",
    "        fits_list.append([fit_func.__name__,list(popt_T), list(perr_T)])\n",
    "    \n",
    "\n",
    "ax1.set_xlabel(x_lbl)\n",
    "ax1.set_ylabel(y_lbl)\n",
    "ax1.set_title(folder.rstrip(r'\\/ '))\n",
    "ax1.set_ylim(bottom=0)\n",
    "ax1.legend(loc=4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# When change to pandas data\n",
    "d1 = dict()\n",
    "param = ['fit1D_x','N']\n",
    "d1['x']=avr_table['folder']\n",
    "d1['y'] = avr_table[tuple(param)]\n",
    "param_std = list(copy(param))\n",
    "param_std[0]+='_std'\n",
    "try:\n",
    "    d1['yerr'] = avr_table[tuple(param_std)]\n",
    "except:\n",
    "    d1['yerr'] = None\n",
    "d1['label']='_'.join(param)\n",
    "errorbar(**d1)\n",
    "legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each picture\n",
    "xs, ys, cs = impr.constract_data_scatter(dataD, shot_typeN, 'fit1D_y',0)\n",
    "# plt.figure(figsize=(13,4))\n",
    "scatter(xs,ys,c=cs,linewidths=0)\n",
    "title(\"Individual data, blue - good, red - bad\")\n",
    "ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show 2D image\n",
    "# imshow(avr_dataD[0.2][1].image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if folder != '':\n",
    "    fig1.savefig(os.path.join('Figures',folder.rstrip(r'\\/ ')+'.png'))\n",
    "    # save pandas table to csv file\n",
    "    avr_table.to_csv(os.path.join(folder,'avr_table.csv'))\n",
    "    try:\n",
    "        with open('all_data.txt', 'rb') as handle:\n",
    "            res_dict = pickle.loads(handle.read())\n",
    "    except FileNotFoundError:\n",
    "        res_dict = {}\n",
    "    except EOFError:\n",
    "        res_dict = {}\n",
    "    res_dict[folder.rstrip(r'\\/ ')]={'description':description,'data':navrD}\n",
    "    with open('all_data.txt', 'wb') as handle:\n",
    "        pickle.dump(res_dict, handle)\n",
    "    with open('all_data.json', 'w') as outfile:\n",
    "        json.dump(res_dict, outfile, cls=impr.JsonCustomEncoder, indent=4)    \n",
    "    print('Figure and data saved!!!')\n",
    "    \n",
    "# to later read json file run following two lines\n",
    "#with open('all_data.json', 'r') as infile:\n",
    "#        ddata = json.load(infile)\n",
    "\n",
    "#save to mongo db\n",
    "# get pickle string of avr_table \n",
    "ss = 'temp'\n",
    "avr_table.to_pickle(ss)\n",
    "with open(ss,'rb') as fl:\n",
    "    line = fl.read()\n",
    "os.remove(ss)\n",
    "# prepear dictionary to load to mongoDB\n",
    "data_to_db = {\n",
    "             'date_meas':datetime.datetime.strptime(current_directory[:10],'%Y_%m_%d'),\n",
    "             'date_mod':datetime.datetime.now(),\n",
    "             'folder':folder,\n",
    "             'meas_type':meas_type,\n",
    "             'labels':[x_lbl, y_lbl],\n",
    "              'conf_params':conf_params,\n",
    "              'fits': fits_list,\n",
    "              'avr_table_pickle':line\n",
    "             }\n",
    "# try to find entery with the same 'date_meas' and 'folder' and either update or create entery\n",
    "res = meas_database.find_one({'date_meas':datetime.datetime.strptime(current_directory[:10],'%Y_%m_%d'),\n",
    "                 'folder':folder})\n",
    "if res:\n",
    "    print('Entery for folder \"%s\" updated' % folder)\n",
    "    meas_database.update_one({'_id':res['_id']},{'$set':data_to_db})\n",
    "else:\n",
    "    print('Entery for folder \"%s\" created' % folder)\n",
    "    meas_database.insert_one(data_to_db)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# part for getting data from mongoDB\n",
    "coursor = meas_database.find()\n",
    "tables = []\n",
    "for item in coursor:\n",
    "    for key in item:\n",
    "        if(key == 'avr_table_pickle'):\n",
    "            tables.append(pickle.loads(item[key]))\n",
    "            print(key,item[key][-20:])\n",
    "        else:\n",
    "            print(key,item[key])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
