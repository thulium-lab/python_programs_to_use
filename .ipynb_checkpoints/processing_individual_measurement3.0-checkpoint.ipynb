{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Description\n",
    "\"\"\"\n",
    "Last modified 08.02.2016\n",
    "Pandas functionality added, now can be saved to database\n",
    "\n",
    "New - sifting works correctly, \n",
    "        in dataD images which are sifted indicated as isgood=False, \n",
    "        fits now use parameter sigma = 'yerr' to calculate fit,\n",
    "        \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To restart remote kernels run code below before restarting this kernel\n",
    "rc1.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%px --targets 0 \n",
    "# to enter kernel qtconsole run this code\n",
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports and initialization\n",
    "%pylab inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "par_dir = os.path.split(os.getcwd())[0]\n",
    "if par_dir not in sys.path:\n",
    "    sys.path.append(par_dir)\n",
    "import inspect\n",
    "import pickle\n",
    "import imp\n",
    "import re\n",
    "import json\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "\n",
    "# from IPython.html import widgets\n",
    "# from IPython.display import display\n",
    "# from IPython.html.widgets import interact, interactive, fixed\n",
    "\n",
    "\n",
    "# import thulium_python_lib.usefull_functions as usfuncs\n",
    "import thulium_python_lib.image_processing_new as impr\n",
    "\n",
    "import ipyparallel as ipp\n",
    "ipp.CompositeError.tb_limit = 1\n",
    "\n",
    "rc1 = ipp.Client()\n",
    "\n",
    "lview = rc1.load_balanced_view()\n",
    "dview = rc1.direct_view()\n",
    "dview['par_dir'] = par_dir\n",
    "# with dview.sync_imports():\n",
    "#     import sys, os    \n",
    "%px import sys, os\n",
    "%px if par_dir not in sys.path: sys.path.append(par_dir)\n",
    "%px import thulium_python_lib.image_processing_new as impr\n",
    "%px import imp\n",
    "%px from ipyparallel import bind_kernel; bind_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to reload library on remote and local engine\n",
    "%px imp.reload(impr)\n",
    "imp.reload(impr)\n",
    "# imp.reload(usfuncs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose working directory and measurement folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# smth like 'D:\\!Data\\2015_08_20' for lab and like '/Users/artemgolovizin/Downloads/2015_08_20' for mac\n",
    "# os.chdir(r'\\\\BIGONE\\!Data\\2015_12_08')\n",
    "os.chdir(r'/Users/artemgolovizin/Documents/lab_data/2016_05_12')\n",
    "# print('Current directory', os.getcwd());\n",
    "\n",
    "# Create folder 'Figures' for saving individual plot\n",
    "if not os.path.exists('Figures'):\n",
    "    os.makedirs('Figures')\n",
    "    print('Folder Figures has been created')\n",
    "    \n",
    "working_directory = ''\n",
    "folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify working folder\n",
    "folder = '43 calib2'\n",
    "working_directory = os.path.join(os.getcwd(),folder)\n",
    "# print('Working directory', working_directory)\n",
    "\n",
    "dirs = [x for x in os.listdir() if re.match('\\d',x)]\n",
    "meas_type, x_lbl, y_lbl, xaxis_calib = impr.get_x_calibration(folder, dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, rearange, average and calibrate\n",
    " Constract loader and averager. For available parameters see help('instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# attempts to use checkboxes for specify workflow\n",
    "from ipywidgets import Checkbox\n",
    "from IPython.display import display\n",
    "\n",
    "aaa = Checkbox(\n",
    "    description='Check me',\n",
    "    value=True,\n",
    ")\n",
    "display(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create loader\n",
    "loader  = impr.Load_Image(dview)\n",
    "# downloading images\n",
    "all_data = loader(working_directory,lview)\n",
    "\n",
    "# rearranging to dictionary\n",
    "dataD = impr.rearrange_data(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create averager\n",
    "averager = impr.Avr_Image(dview,do_sifting=True,conf_int=0.2)\n",
    "# averaging data\n",
    "avr_dataD = averager(dataD,lview)\n",
    "\n",
    "# construct new data dictionary without image and calibration atoms number, size and x-axis\n",
    "navrD = impr.mod_avrData(avr_dataD, xaxis_calib, impr.N_atoms(width=0.5, delta = 5), impr.real_size)\n",
    "\n",
    "avr_table = impr.get_pandas_table(navrD)\n",
    "# for plotting sifted image\n",
    "\n",
    "#imshow(imread('1 от частоты амплитудной модуляции аома верди (5) 3.9W/26ms/2_1.png'))\n",
    "#colorbar()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# convention table for filenames\n",
    "impr.meas_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct data based on measurement type and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shot_typeN - for now only 1, if there will be calibration - 1 or more\n",
    "shot_typeN = 1\n",
    "\n",
    "# description to add to all_data.txt file\n",
    "description = dict()\n",
    "description['meas_type'] = meas_type\n",
    "description['x_label'] = x_lbl\n",
    "description['y_label'] = y_lbl\n",
    "\n",
    "#meas_type = 'T' # here one can specify type to get desired plots\n",
    "# meas_type = 'T'\n",
    "fit_func = None\n",
    "fig1, ax1 = subplots()\n",
    "if meas_type == 'T':\n",
    "    # construct data with cloud expansion on both coordinates\n",
    "    # first set of data  - Temperature X\n",
    "    d1 = impr.get_avr_data(navrD, shot_typeN, 'fit1D_x',2)\n",
    "    d1['fmt']='ro'\n",
    "    d1['label']='fit1D_x'\n",
    "    #impr.drop_by_number(d1,5)\n",
    "    #impr.drop_by_x(d1,130,160)\n",
    "\n",
    "    # second set of data  - Temperature Y\n",
    "    d2 = impr.get_avr_data(navrD, shot_typeN,  'fit1D_y',2)\n",
    "    d2['fmt']='bo'\n",
    "    d2['label'] = 'fit1D_y'\n",
    "    #impr.drop_by_number(d2,5)\n",
    "    \n",
    "    # fit cloud expansion\n",
    "    fit_func = usfuncs.cloud_expansion0\n",
    "    popt_T, pcov_T = curve_fit(fit_func, d1['x'], d1['y'], p0=(d1['y'][0],20))\n",
    "    popt_T2, pcov_T2 = curve_fit(fit_func, d2['x'], d2['y'], p0=(d2['y'][0], 20))\n",
    "    print('Fit parameters X, Y:\\n' + usfuncs.construct_fit_description(fit_func, list(zip(popt_T,popt_T2))))\n",
    "    \n",
    "    # plot data and fits  ADD T VALUE ON PLOT\n",
    "    ax1.errorbar(**d2)\n",
    "    ax1.errorbar(**d1)\n",
    "    ax1.plot(linspace(min(d1['x']),max(d1['x']),100), fit_func(linspace(min(d1['x']),max(d1['x']),100),*popt_T),'k', label='Tx=%.2f'%(popt_T[0]))\n",
    "    ax1.plot(linspace(min(d2['x']),max(d2['x']),100), fit_func(linspace(min(d2['x']),max(d2['x']),100),*popt_T2),'k', label='Ty=%.2f'%(popt_T2[0]))\n",
    "    ax1.set_xlim(min(d1['x'])-1, max(d1['x'])+1)\n",
    "    # add information about fits to description\n",
    "    description['fit1D_x'] =  popt_T\n",
    "    description['fit1D_y'] =  popt_T2\n",
    "    description['fit-function'] = fit_func.__name__\n",
    "else:\n",
    "    # construct data, param - what value to use\n",
    "    param = 'fit2D'\n",
    "    d1 = impr.get_avr_data(navrD, shot_typeN, param,0)\n",
    "    d1['fmt']='ro'\n",
    "    d1['label']=param\n",
    "    #impr.drop_by_number(d1,*range(20,len(d1['x'])))\n",
    "    #impr.drop_by_x(d1,130,160)\n",
    "    \n",
    "    # fit_func - which function to use to fit data  here one can put conditions on meas_type to choose fit\n",
    "    popt_T = None\n",
    "#     fit_func = usfuncs.exp_decay\n",
    "#     popt_T, pcov_T = curve_fit(fit_func, d1['x'], d1['y'], p0=(d1['y'][0], 100,0))\n",
    "#     #popt_T, pcov_T = curve_fit(fit_func, d1['x'], d1['y'], p0=(-d1['y'][0], d1['x'][argmin(d1['y'])],0.1,d1['y'][0]))\n",
    "#     print('Fit parameters:\\n' + usfuncs.construct_fit_description(fit_func, popt_T))\n",
    "    \n",
    "    # plot data and fits\n",
    "    ax1.errorbar(**d1)\n",
    "    if fit_func != None:\n",
    "        ax1.plot(linspace(min(d1['x']),max(d1['x']),100), fit_func(linspace(min(d1['x']),max(d1['x']),100),*popt_T),'k', label='fit X')\n",
    "    if fit_func != None:\n",
    "        fit_label = fit_func.__name__ + ' fit:\\n' + usfuncs.construct_fit_description(fit_func, popt_T)\n",
    "        ax1.text(0.01,0.01,fit_label,transform=ax1.transAxes)\n",
    "        description['fit'] =  popt_T\n",
    "        description['fit-function'] = fit_func.__name__\n",
    "    \n",
    "\n",
    "ax1.set_xlabel(x_lbl)\n",
    "ax1.set_ylabel(y_lbl)\n",
    "ax1.set_title(folder.rstrip(r'\\/ '))\n",
    "ax1.set_ylim(bottom=0)\n",
    "ax1.legend(loc='best')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d1 = dict()\n",
    "param = ['fit1D_x','x0']\n",
    "d1['x']=avr_table['folder']\n",
    "d1['y'] = avr_table[tuple(param)]\n",
    "param_std = list(copy(param))\n",
    "param_std[0]+='_std'\n",
    "try:\n",
    "    d1['yerr'] = avr_table[tuple(param_std)]\n",
    "except:\n",
    "    d1['yerr'] = None\n",
    "d1['label']='_'.join(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each picture\n",
    "shot_typeN=2\n",
    "xs, ys, cs = impr.constract_data_scatter(dataD, shot_typeN, 'fit1D_y',0)\n",
    "plt.figure(figsize=(13,4))\n",
    "scatter(xs,ys,c=cs,linewidths=0)\n",
    "title(\"Individual data, blue - good, red - bad\")\n",
    "ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show 2D image\n",
    "# imshow(avr_dataD[0.2][1].image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if folder != '':\n",
    "    fig1.savefig(os.path.join('Figures',folder.rstrip(r'\\/ ')+'.png'))\n",
    "    try:\n",
    "        with open('all_data.txt', 'rb') as handle:\n",
    "            res_dict = pickle.loads(handle.read())\n",
    "    except FileNotFoundError:\n",
    "        res_dict = {}\n",
    "    except EOFError:\n",
    "        res_dict = {}\n",
    "    res_dict[folder.rstrip(r'\\/ ')]={'description':description,'data':navrD}\n",
    "    with open('all_data.txt', 'wb') as handle:\n",
    "        pickle.dump(res_dict, handle)\n",
    "    with open('all_data.json', 'w') as outfile:\n",
    "        json.dump(res_dict, outfile, cls=impr.JsonCustomEncoder, indent=4)    \n",
    "    print('Figure and data saved!!!')\n",
    "    \n",
    "# to later read json file run following two lines\n",
    "#with open('all_data.json', 'r') as infile:\n",
    "#        ddata = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to check how good is fit\n",
    "perr = np.sqrt(np.diag(pcov_T))\n",
    "print(perr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# some attempts to use pandas for individual images data\n",
    "def construct_DataFrame(dictionary):\n",
    "    indexes = []\n",
    "    data = []\n",
    "    tr_table = {'fit1D':['N','x0','sigma','bgnd'], \n",
    "            'fit2D':['N','y0','x0','sigma_y','sigma_x','bgnd'],\n",
    "            'center_pos':['x','y']}\n",
    "    for key,value in dictionary.items():\n",
    "        \n",
    "        flag = False\n",
    "        if key == 'image':\n",
    "            continue\n",
    "        for tkey in tr_table:\n",
    "            if key.startswith(tkey):\n",
    "                for i, name in enumerate(tr_table[tkey]):\n",
    "                    indexes.append((key,name))\n",
    "                    data.append(value[i])\n",
    "                flag = True\n",
    "                continue\n",
    "        if not flag:    \n",
    "            indexes.append((key,''))\n",
    "            data.append(value)\n",
    "    res = pd.DataFrame(data, index=pd.MultiIndex.from_tuples(indexes)).T\n",
    "    return res\n",
    "data_pd = []\n",
    "for item in all_data:\n",
    "    data_pd.append(construct_DataFrame(item.__dict__))\n",
    "data_pd = pd.concat(data_pd,ignore_index=True).convert_objects(convert_numeric=True)\n",
    "for folder in data_pd.folderN.unique():\n",
    "    for tp in data_pd.shot_typeN.unique():\n",
    "        med = data_pd[(data_pd.folderN==folder)&  (data_pd.shot_typeN==tp)].total.median()\n",
    "#         print(abs(data_pd[(data_pd.folderN==folder)&  (data_pd.shot_typeN==tp)].total - med)/med < 0.1)\n",
    "        data_pd.loc[(data_pd.folderN==folder)&  (data_pd.shot_typeN==tp),'isgood'] = \n",
    "            abs(data_pd[(data_pd.folderN==folder)&  (data_pd.shot_typeN==tp)].total - med)/med < 0.1\n",
    "\n",
    "if len(data_pd.shot_typeN.unique()) == 2:\n",
    "    data_pd.loc[data_pd.shot_typeN==1,'total_small'] = np.divide(data_pd.loc[data_pd.shot_typeN==1,'total_small'],\n",
    "                                                                 data_pd.loc[data_pd.shot_typeN==2,'total_small'])\n",
    "    data_pd.loc[data_pd.shot_typeN==1,'isgood'] = np.multiply(data_pd.loc[data_pd.shot_typeN==1,'isgood'],\n",
    "                                                              data_pd.loc[data_pd.shot_typeN==2,'isgood'])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
