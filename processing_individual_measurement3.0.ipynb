{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "\n",
    "\"\"\"To do - add some checks before in normalization on case of absence of calibration shot\n",
    "\n",
    "Last modified 23.05.2016\n",
    "    Normalization is realized, but for now all functions are in this file.\n",
    "    When tested should be transfered to the library\n",
    "    \n",
    "Modified 11.02.2016\n",
    "    Added mongoDB support\n",
    "    pandas avr_table dumps to csv file in 'folder' directory \n",
    "\n",
    "08.02.2016\n",
    "Pandas functionality added, now can be saved to database\n",
    "\n",
    "New - sifting works correctly, \n",
    "        in dataD images which are sifted indicated as isgood=False, \n",
    "        fits now use parameter sigma = 'yerr' to calculate fit,\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To restart remote kernels run code below before restarting this kernel\n",
    "rc1.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "%%px --targets 0 \n",
    "# to enter kernel qtconsole run this code\n",
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports and initialization\n",
    "%pylab inline\n",
    "\n",
    "import sys, os\n",
    "par_dir = os.path.split(os.getcwd())[0]\n",
    "if par_dir not in sys.path:\n",
    "    sys.path.append(par_dir)\n",
    "    \n",
    "import inspect,pickle,imp,re,json,copy\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "\n",
    "from ipywidgets import Checkbox\n",
    "from IPython.display import display\n",
    "\n",
    "import thulium_python_lib.usefull_functions as usfuncs\n",
    "import thulium_python_lib.image_processing_new as impr\n",
    "\n",
    "import ipyparallel as ipp\n",
    "ipp.CompositeError.tb_limit = 1\n",
    "rc1 = ipp.Client()\n",
    "lview = rc1.load_balanced_view()\n",
    "dview = rc1.direct_view()\n",
    "dview['par_dir'] = par_dir\n",
    "%px import sys, os, imp\n",
    "%px if par_dir not in sys.path: sys.path.append(par_dir)\n",
    "%px import thulium_python_lib.image_processing_new as impr\n",
    "# %px from ipyparallel import bind_kernel; bind_kernel()\n",
    "\n",
    "import pymongo, datetime\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "#start mongoDB client (mongod server should be launched)\n",
    "client = MongoClient('mongodb://192.168.1.15:27017/')\n",
    "meas_database = client.measData.meas_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to reload library on remote and local engine\n",
    "%px imp.reload(impr)\n",
    "imp.reload(impr)\n",
    "# imp.reload(usfuncs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now:\n",
    "#### Choose working directory and measurement folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ],
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# smth like 'D:\\!Data\\2015_08_20' for lab and like '/Users/artemgolovizin/Downloads/2015_08_20' for mac\n",
    "os.chdir(r'\\\\BIGONE\\!Data\\2016_05_12')\n",
    "# os.chdir(r'/Users/artemgolovizin/Downloads/2015_08_20/')\n",
    "current_directory = os.path.split(os.getcwd())[-1]\n",
    "# Create folder 'Figures' for saving individual plot\n",
    "if not os.path.exists('Figures'):\n",
    "    os.makedirs('Figures')\n",
    "    print('Folder Figures has been created')\n",
    "working_directory = ''\n",
    "folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify working folder\n",
    "folder = '05 as 01 f=363.1/'\n",
    "working_directory = os.path.join(os.getcwd(),folder)\n",
    "\n",
    "dirs = [x for x in os.listdir() if re.match('\\d',x)]\n",
    "meas_type, conf_params, x_lbl, y_lbl, xaxis_calib = impr.get_x_calibration(folder, dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkboxes for specify do normalization or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#checkboxes for specify workflow\n",
    "do_individual_image_normalization = Checkbox(\n",
    "     description='Do individual image normalization?',\n",
    "     value=False,\n",
    ")\n",
    "display(do_individual_image_normalization)\n",
    "\n",
    "do_average_image_normalization = Checkbox(\n",
    "     description='Do average image normalization?',\n",
    "     value=False,\n",
    ")\n",
    "display(do_average_image_normalization)\n",
    "\n",
    "do_two_gaussian_fit = Checkbox(\n",
    "     description='do_two_gaussian_fit?',\n",
    "     value=True,\n",
    ")\n",
    "display(do_two_gaussian_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, rearange, average and calibrate\n",
    " Constract loader and averager. For available parameters see help('instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create loader\n",
    "loader  = impr.Load_Image(dview, do_fit1D_x=True, do_fit1D_y=True)\n",
    "# downloading images\n",
    "all_data = loader(working_directory,lview)\n",
    "\n",
    "# rearranging to dictionary\n",
    "dataD = impr.rearrange_data(all_data)\n",
    "\n",
    "# normalization\n",
    "if do_individual_image_normalization.value:\n",
    "    dataD = normalise_individual_image(dataD, 1, 2, 'fit1D_x', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create averager\n",
    "averager = impr.Avr_Image(dview,do_sifting=True,conf_int=0.1)\n",
    "# averaging data and fitting\n",
    "avr_dataD = averager(dataD,lview)\n",
    "# normalization\n",
    "if do_average_image_normalization.value:\n",
    "    avr_dataD = normalize_average_image(avr_dataD,1,2,'fit1D_x',0)\n",
    "if do_two_gaussian_fit.value:\n",
    "#     avr_dataD = impr.two_gaussian_fit(avr_dataD,p00=[15,10,76,20,40,0],fix_N_cool=True)\n",
    "    avr_dataD = impr.two_gaussian_fit2(avr_dataD)\n",
    "\n",
    "# construct new data dictionary without image and calibration atoms number, size and x-axis\n",
    "navrD = impr.mod_avrData(avr_dataD, xaxis_calib, impr.N_atoms(gain=200, exposure=500, power=6.3, width=1.85, delta = 6), impr.real_size)\n",
    "\n",
    "avr_table = impr.get_pandas_table2(navrD)\n",
    "# for plotting sifted image\n",
    "#imshow(imread('1 от частоты амплитудной модуляции аома верди (5) 3.9W/26ms/2_1.png'))\n",
    "#colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct data based on measurement type and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     12
    ],
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# shot_typeN - for now only 1, if there will be calibration - 1 or more\n",
    "shot_typeN = 1\n",
    "\n",
    "# description to add to all_data.txt file\n",
    "description = dict()\n",
    "description['meas_type'] = meas_type\n",
    "description['x_label'] = x_lbl\n",
    "description['y_label'] = y_lbl\n",
    "fit_func = None\n",
    "fits_list = []\n",
    "fig1, ax1 = subplots(figsize=(10,5))\n",
    "if meas_type == 'T':\n",
    "    # construct data with cloud expansion on both coordinates\n",
    "    # first set of data  - Temperature X\n",
    "    d=[]\n",
    "    fit_func = usfuncs.cloud_expansion0\n",
    "    for suffix in ('x','y'):\n",
    "        if do_two_gaussian_fit.value: \n",
    "            indexs = [3,4]\n",
    "            attr = 'fit_two_gaussian1D_'\n",
    "        else:\n",
    "            indexs = [2]\n",
    "            attr = 'fit1D_'\n",
    "        for i in indexs:\n",
    "            d1 = impr.get_avr_data(navrD, shot_typeN, attr+suffix,i)\n",
    "            impr.drop_by_number(d1,*range(len(d1['x'])-4,len(d1['x'])))\n",
    "#             ax1.errorbar(**d1)\n",
    "             \n",
    "            popt, pcov = curve_fit(fit_func, d1['x'], d1['y'], p0=(20,d1['y'][0]),bounds=(0,np.inf))\n",
    "            perr = np.sqrt(np.diag(pcov))\n",
    "            fits_list.append([fit_func.__name__,list(popt), list(perr)])\n",
    "            d1['label']=attr+suffix+' T=%.2f$\\pm$%.1f'%(popt[0],perr[0])\n",
    "            d1['fmt']='o'\n",
    "            d.append(d1)\n",
    "            ax1.errorbar(**d1)\n",
    "            xx1 = linspace(min(d1['x']),max(d1['x']),100)\n",
    "            ax1.plot(xx1, fit_func(xx1,*popt),ax1.lines[-1]._color)#, label='Tx=%.2f$\\pm$%.1f'%(popt_T[0],perr_T[0])\n",
    "            description[attr+suffix] =  popt\n",
    "            \n",
    "            \n",
    "#     d1 = impr.get_avr_data(navrD, shot_typeN, 'fit1D_x',2)\n",
    "#     d1['fmt']='ro'\n",
    "#     d1['label']='fit1D_x'\n",
    "#     #impr.drop_by_number(d1,10,9,8)\n",
    "#     #impr.drop_by_x(d1,130,160)\n",
    "\n",
    "#     # second set of data  - Temperature Y\n",
    "#     d2 = impr.get_avr_data(navrD, shot_typeN,  'fit1D_y',2)\n",
    "#     d2['fmt']='bo'\n",
    "#     d2['label'] = 'fit1D_y'\n",
    "#     #impr.drop_by_number(d2,10,9,8)\n",
    "#     #impr.drop_by_x(d2,14)\n",
    "    \n",
    "#     # fit cloud expansion\n",
    "#     fit_func = usfuncs.cloud_expansion0\n",
    "#     #fit_func = cloud_expansion_fixed_t0\n",
    "#     popt_T, pcov_T = curve_fit(fit_func, d1['x'], d1['y'], p0=(20,d1['y'][0]),bounds=(0,np.inf))\n",
    "#     perr_T = np.sqrt(np.diag(pcov_T))\n",
    "#     fits_list.append([fit_func.__name__,list(popt_T), list(perr_T)])\n",
    "#     popt_T2, pcov_T2 = curve_fit(fit_func, d2['x'], d2['y'], p0=(20,d2['y'][0]),bounds=(0,np.inf))\n",
    "#     perr_T2 = np.sqrt(np.diag(pcov_T2))\n",
    "#     fits_list.append([fit_func.__name__,list(popt_T2), list(perr_T2)])\n",
    "#     print('Fit parameters X, Y:\\n' + usfuncs.construct_fit_description(fit_func, list(zip(popt_T,popt_T2))))\n",
    "    \n",
    "#     # plot data and fits \n",
    "#     ax1.errorbar(**d2)\n",
    "#     ax1.errorbar(**d1)\n",
    "#     xx1 = linspace(min(d1['x']),max(d1['x']),100)\n",
    "#     ax1.plot(xx1, fit_func(xx1,*popt_T),'r', label='Tx=%.2f$\\pm$%.1f'%(popt_T[0],perr_T[0]))\n",
    "#     xx2=linspace(min(d2['x']),max(d2['x']),100)\n",
    "#     ax1.plot(xx2, fit_func(xx2,*popt_T2), 'b', label='Ty=%.2f$\\pm$%.1f'%(popt_T2[0],perr_T2[0]))\n",
    "    \n",
    "    \n",
    "#     ax1.set_xlim(min(d1['x'])-1, max(d1['x'])+1)\n",
    "#     # add information about fits to description\n",
    "#     description['fit1D_x'] =  popt_T\n",
    "#     description['fit1D_y'] =  popt_T2\n",
    "    description['fit-function'] = fit_func.__name__\n",
    "else:\n",
    "    #construct data, param - what value to use\n",
    "    param = ['fit1D_x',0]\n",
    "    d1 = impr.get_avr_data(navrD, shot_typeN, *param)\n",
    "    d1['fmt']='r*'\n",
    "    d1['label']=param\n",
    "#     d1['yerr']=None\n",
    "#     impr.drop_by_number(d1,1,0)\n",
    "    #impr.drop_by_x(d1,130,160)\n",
    "    \n",
    "    # fit_func - which function to use to fit data  here one can put conditions on meas_type to choose fit\n",
    "    #fit_func = usfuncs.exp_decay_no_bg\n",
    "    #popt_T, pcov_T = curve_fit(fit_func, d1['x'], d1['y'], p0=(d1['y'][0], 100))\n",
    "    #popt_T, pcov_T = curve_fit(fit_func, d1['x'], d1['y'], p0=(-d1['y'][0], d1['x'][argmin(d1['y'])],0.1,d1['y'][0]))\n",
    "    #print('Fit parameters:\\n' + usfuncs.construct_fit_description(fit_func, popt_T))\n",
    "    #perr_T = np.sqrt(np.diag(pcov_T))\n",
    "    if meas_type == 'CL':\n",
    "        fit_func = usfuncs.lorentz\n",
    "        popt_T, pcov_T = curve_fit(fit_func, d1['x'], d1['y'], \n",
    "                                   p0=(max(d1['y'])/2,d1['x'][argmin(d1['y'])],(max(d1['x'])-min(d1['x']))/4, max(d1['y'])))\n",
    "#             max(d1['x']),d1['x'][argmin(d1['x'])],(max(d1['x'])+min(d1['x']))/2, max(d1['x'])\n",
    "        perr_T = np.sqrt(np.diag(pcov_T))\n",
    "        print(popt_T)\n",
    "        print(perr_T)\n",
    "    if meas_type == 'LT':\n",
    "#         impr.drop_by_number(d1,6,7)\n",
    "        fit_func = usfuncs.exp_plus_tw_body_decay_no_bg\n",
    "        popt_T, pcov_T = curve_fit(fit_func, d1['x'], d1['y'], \n",
    "                                   p0=(d1['y'][0],1000,1e-8))#max(d1['x']),d1['x'][argmin(d1['x'])],(max(d1['x'])+min(d1['x']))/2, max(d1['x'])\n",
    "        perr_T = np.sqrt(np.diag(pcov_T))\n",
    "        print(popt_T)\n",
    "        print(perr_T)\n",
    "        print('Fit parameters:\\n' + usfuncs.construct_fit_description(fit_func, popt_T))\n",
    "    # plot data and fits\n",
    "    ax1.errorbar(**d1)\n",
    "    if fit_func != None:\n",
    "        ax1.plot(linspace(min(d1['x']),max(d1['x']),100), fit_func(linspace(min(d1['x']),max(d1['x']),100),*popt_T),'k', label='fit X')\n",
    "        fit_label = fit_func.__name__ + ' fit:\\n' + usfuncs.construct_fit_description(fit_func, list(zip(popt_T,perr_T)),sep='$\\pm$')\n",
    "        ax1.text(0.01,0.01,fit_label,transform=ax1.transAxes)\n",
    "        description['fit'] =  popt_T\n",
    "        description['fit-function'] = fit_func.__name__\n",
    "        fits_list.append([fit_func.__name__,list(popt_T), list(perr_T)])\n",
    "    \n",
    "\n",
    "ax1.set_xlabel(x_lbl)\n",
    "ax1.set_ylabel(y_lbl)\n",
    "ax1.set_title(folder.rstrip(r'\\/ '))\n",
    "ax1.set_ylim(bottom=0)\n",
    "ax1.legend(loc=2)\n",
    "\n",
    "print('Number of atoms %d +- %i'%(avr_table.T[0].fit1D_x.N,avr_table.T[0].fit1D_x_std.N))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gf = avr_dataD[5][1]\n",
    "im = sum(gf.image,0)\n",
    "xx = arange(len(im))\n",
    "# fit_func = two_gaussian\n",
    "# popt, pcov = curve_fit(fit_func, xx, im, p0=(100,50, 73,10,40,0))\n",
    "\n",
    "plot(xx,im)\n",
    "plot(xx,impr.two_gaussian2(xx,*gf.fit_two_gaussian1D_x),'k')\n",
    "# perr = np.sqrt(np.diag(pcov))\n",
    "fit_func = impr.gaussian\n",
    "popt1, pcov1 = curve_fit(fit_func, xx, im, p0=(100,73,40,0))\n",
    "plot(xx,fit_func(xx,*popt1),'y')\n",
    "\n",
    "# print(popt1)\n",
    "popt = gf.fit_two_gaussian1D_x\n",
    "print(popt)\n",
    "plot(xx, impr.gaussian(xx,popt[0]*popt[1],popt[2],popt[3],popt[-1]),'r')\n",
    "plot(xx, impr.gaussian(xx,popt[0]*(1-popt[1]),popt[2],popt[4],popt[-1]),'b')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gf = avr_dataD[6][1]\n",
    "im = sum(gf.image,0)\n",
    "xx = arange(len(im))\n",
    "# fit_func = two_gaussian\n",
    "# popt, pcov = curve_fit(fit_func, xx, im, p0=(100,50, 73,10,40,0))\n",
    "\n",
    "plot(xx,im)\n",
    "plot(xx,impr.two_gaussian(xx,*gf.fit_two_gaussian1D_x),'k')\n",
    "# perr = np.sqrt(np.diag(pcov))\n",
    "fit_func = impr.gaussian\n",
    "popt1, pcov1 = curve_fit(fit_func, xx, im, p0=(100,73,40,0))\n",
    "plot(xx,fit_func(xx,*popt1),'y')\n",
    "\n",
    "# print(popt1)\n",
    "popt = gf.fit_two_gaussian1D_x\n",
    "print(popt)\n",
    "plot(xx, impr.gaussian(xx,popt[0],popt[2],popt[3],popt[-1]),'r')\n",
    "plot(xx, impr.gaussian(xx,popt[1],popt[2],popt[4],popt[-1]),'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for each picture\n",
    "shot_typeN = 1\n",
    "xs, ys, cs = impr.constract_data_scatter(dataD, shot_typeN, 'fit1D_x',0)\n",
    "# plt.figure(figsize=(13,4))\n",
    "scatter(xs,ys,c=cs,linewidths=0)\n",
    "title(\"Individual data, blue - good, red - bad\")\n",
    "ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save all data\n",
    "if folder != '':\n",
    "    fig1.savefig(os.path.join('Figures',folder.rstrip(r'\\/ ')+'.png'))\n",
    "    # save pandas table to csv file\n",
    "    avr_table.to_csv(os.path.join(folder,'avr_table.csv'))\n",
    "    try:\n",
    "        with open('all_data.txt', 'rb') as handle:\n",
    "            res_dict = pickle.loads(handle.read())\n",
    "    except FileNotFoundError:\n",
    "        res_dict = {}\n",
    "    except EOFError:\n",
    "        res_dict = {}\n",
    "    res_dict[folder.rstrip(r'\\/ ')]={'description':description,'data':navrD}\n",
    "    with open('all_data.txt', 'wb') as handle:\n",
    "        pickle.dump(res_dict, handle)\n",
    "    with open('all_data.json', 'w') as outfile:\n",
    "        json.dump(res_dict, outfile, cls=impr.JsonCustomEncoder, indent=4)    \n",
    "    print('Figure and data saved!!!')\n",
    "\n",
    "#save to mongo db\n",
    "# get pickle string of avr_table \n",
    "ss = 'temp'\n",
    "avr_table.to_pickle(ss)\n",
    "with open(ss,'rb') as fl:\n",
    "    line = fl.read()\n",
    "os.remove(ss)\n",
    "# prepear dictionary to load to mongoDB\n",
    "data_to_db = {\n",
    "             'date_meas':datetime.datetime.strptime(current_directory[:10],'%Y_%m_%d'),\n",
    "             'date_mod':datetime.datetime.now(),\n",
    "             'folder':folder,\n",
    "             'meas_type':meas_type,\n",
    "             'labels':[x_lbl, y_lbl],\n",
    "              'conf_params':conf_params,\n",
    "              'fits': fits_list,\n",
    "              'avr_table_pickle':line\n",
    "             }\n",
    "# try to find entery with the same 'date_meas' and 'folder' and either update or create entery\n",
    "res = meas_database.find_one({'date_meas':datetime.datetime.strptime(current_directory[:10],'%Y_%m_%d'),\n",
    "                 'folder':folder})\n",
    "if res:\n",
    "    print('Entery for folder \"%s\" updated' % folder)\n",
    "    meas_database.update_one({'_id':res['_id']},{'$set':data_to_db})\n",
    "else:\n",
    "    print('Entery for folder \"%s\" created' % folder)\n",
    "    meas_database.insert_one(data_to_db)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# When change to pandas data\n",
    "d1 = dict()\n",
    "param = ['fit1D_x','N']\n",
    "d1['x']=avr_table['folder']\n",
    "d1['y'] = avr_table[tuple(param)]\n",
    "param_std = list(copy(param))\n",
    "param_std[0]+='_std'\n",
    "try:\n",
    "    d1['yerr'] = avr_table[tuple(param_std)]\n",
    "except:\n",
    "    d1['yerr'] = None\n",
    "d1['label']='_'.join(param)\n",
    "errorbar(**d1)\n",
    "legend(loc='best')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# part for getting data from mongoDB\n",
    "coursor = meas_database.find()\n",
    "tables = []\n",
    "for item in coursor:\n",
    "    for key in item:\n",
    "        if(key == 'avr_table_pickle'):\n",
    "            tables.append(pickle.loads(item[key]))\n",
    "            print(key,item[key][-20:])\n",
    "        else:\n",
    "            print(key,item[key])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# to delite some entery\n",
    "meas_database.delete_one({'folder':\"01 T preramp_a/\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# this cell is now for calibration\n",
    "# as it is not yet tested I do not put it into library what should be done after a while\n",
    "def get_value(obj, attribute, index):\n",
    "    \"\"\"retruns obj.attibute[index] or obj.attribute if index is not defined\"\"\"\n",
    "    if index != None:\n",
    "        return getattr(obj,attribute)[index]\n",
    "    else:\n",
    "        return getattr(obj,attribute)\n",
    "    \n",
    "def normalise_individual_image(dictionary_r, signal_shot, calibration_shot, attribute, index=None, do_fit2D = False):\n",
    "    \"\"\"normalize each image using attribute[index] value - usually 'total' or 'x_data_fit[0]'\n",
    "        returns constracted dictionary (like what returns 'load_data()' function\"\"\"\n",
    "    # copy dictionary to normalize it\n",
    "    dictionary = copy.deepcopy(dictionary_r)\n",
    "    for folderN, f_dict in dictionary.items():\n",
    "        # calculate median for calibration images for current folder\n",
    "        median_calibration = median([get_value(c_elem,attribute,index) for c_elem in f_dict[calibration_shot]])\n",
    "        for s_elem in f_dict[signal_shot]:\n",
    "            c_elems = [c_elem for c_elem in f_dict[calibration_shot] if c_elem.shotN == s_elem.shotN]\n",
    "            if c_elems == []:\n",
    "                print('s_elem.image_url has no calibration image')\n",
    "                continue\n",
    "            coeffitient = get_value(c_elems[0],attribute,index) / median_calibration\n",
    "            s_elem.image /= coeffitient\n",
    "            s_elem.total /= coeffitient\n",
    "            if hasattr(s_elem,'fit1D_x'):\n",
    "                s_elem.fit1D_x[0] /=coeffitient\n",
    "                s_elem.fit1D_x[-1] /=coeffitient\n",
    "            if hasattr(s_elem,'fit1D_y'):\n",
    "                s_elem.fit1D_y[0] /=coeffitient\n",
    "                s_elem.fit1D_y[-1] /=coeffitient\n",
    "            if hasattr(s_elem, 'fit2D'):\n",
    "                s_elem.fit2D[0] /= coeffitient\n",
    "                s_elem.fit2D[-1] /= coeffitient\n",
    "            if hasattr(s_elem,'total_small'):\n",
    "                s_elem.total_small /= coeffitient\n",
    "    print('Normalization is complited')\n",
    "    return dictionary\n",
    "def normalize_average_image(dictionary_r, signal_shot, calibration_shot, attribute, index=None):\n",
    "    # copy dictionary to normalize it\n",
    "    dictionary = copy.deepcopy(dictionary_r)\n",
    "    # calculate mean for calibration images for all folders\n",
    "    median_calibration = mean([get_value(item[calibration_shot],attribute,index) for item in dictionary.values()])\n",
    "    for folder in dictionary:\n",
    "        try:\n",
    "            s_elem = dictionary[folder][signal_shot]\n",
    "            c_elem = dictionary[folder][calibration_shot]\n",
    "            coeffitient = get_value(c_elem,attribute,index) / median_calibration\n",
    "            s_elem.image /= coeffitient\n",
    "            s_elem.total /= coeffitient\n",
    "            if hasattr(s_elem,'fit1D_x'):\n",
    "                s_elem.fit1D_x[0] /=coeffitient\n",
    "                s_elem.fit1D_x[-1] /=coeffitient\n",
    "            if hasattr(s_elem,'fit1D_y'):\n",
    "                s_elem.fit1D_y[0] /=coeffitient\n",
    "                s_elem.fit1D_y[-1] /=coeffitient\n",
    "            if hasattr(s_elem, 'fit2D'):\n",
    "                s_elem.fit2D[0] /= coeffitient\n",
    "                s_elem.fit2D[-1] /= coeffitient\n",
    "            if hasattr(s_elem,'total_small'):\n",
    "                s_elem.total_small /= coeffitient\n",
    "        except:\n",
    "            # I do not know what exeption may by so for now it catches all of them (nost likely some image is not good)\n",
    "            print('Something wronge with average data in folder ',folder)\n",
    "    print('Normalization is complited')\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "center = 416.66\n",
    "delta = 0.005\n",
    "N=50\n",
    "scans = np.concatenate(([center-3*N*delta,center-2*N*delta],arange(center-N*delta,center+N*delta,delta),[center+2*N*delta,center+3*N*delta]))\n",
    "shuffle(scans)\n",
    "' '.join((str(i) for i in scans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "scans = arange(416.55,416.8,0.01)\n",
    "# shuffle(scans)\n",
    "' '.join((str(i) for i in scans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stern-Gerlakh handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat = avr_dataD[4][1]\n",
    "zz = impr.real_size(arange(dat.image.shape[0]))\n",
    "yy2 = sum(dat.image,axis=1)\n",
    "ms = range(-4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Stern_Gerlah_fit_numction(zz, z0, distance,width,background, *ampls):\n",
    "    \"\"\"Function fitfunc(zz, z0, distance,width,background, *ampls) to fit image in `Stern-Gerlah experiment.\n",
    "        z0 - position of m_f=0 cloud zz[-1]/2\n",
    "        distance - displacement between clouds zz[-1]/10\n",
    "        width - cloud width in gaussian fit  zz[-1]/15\n",
    "        background 0\n",
    "        *ampls - unpucked umplitudes of gaussians max(yy2)*width[zz[-1]/15] \"\"\"\n",
    "    res = zeros_like(zz)\n",
    "    res += background\n",
    "    for i,m in enumerate(ms):\n",
    "        res += impr.gaussian(zz, ampls[i],z0+m*distance,width,0)\n",
    "    return res\n",
    "\n",
    "def Stern_Gerlah_fit_numction_fixed(zz,background, *ampls):\n",
    "    \"\"\"Function fitfunc(zz, z0, distance,width,background, *ampls) to fit image in `Stern-Gerlah experiment.\n",
    "        z0 - position of m_f=0 cloud zz[-1]/2\n",
    "        distance - displacement between clouds zz[-1]/10\n",
    "        width - cloud width in gaussian fit  zz[-1]/15\n",
    "        background 0\n",
    "        *ampls - unpucked umplitudes of gaussians max(yy2)*width[zz[-1]/15] \"\"\"\n",
    "    z0 = 1750\n",
    "    distance = 320\n",
    "    width = 700\n",
    "    res = zeros_like(zz)\n",
    "    res += background\n",
    "    for i,m in enumerate(ms):\n",
    "        res += impr.gaussian(zz, ampls[i],z0+m*distance,width,0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# zz and yy come from above\n",
    "# yy2 = sum(yy[:,150:250],1)\n",
    "popt, pcov = curve_fit(Stern_Gerlah_fit_numction_fixed, zz, yy2, p0=(0,*[1e3]*9),bounds=(0,inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(zz,Stern_Gerlah_fit_numction_fixed(zz,*popt))\n",
    "plot(zz,yy2)\n",
    "background, *ampls = popt\n",
    "z0 = 1750\n",
    "distance = 330\n",
    "width = 680\n",
    "for i,m in enumerate(ms):\n",
    "    plot(zz,impr.gaussian(zz, ampls[i],z0+m*distance,width,0),label=m)\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd = pd.DataFrame.from_csv('Data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd = dd/dd.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ddb = dd.iloc[:-8,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd.set_index(['B'.dd.B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(ddb.B,ddb.index)\n",
    "plot(ddb.B, sq(ddb.B,*popt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sq(x,a,b,c):\n",
    "    return a - b*sqrt(c-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(sq,ddb.B, ddb.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
